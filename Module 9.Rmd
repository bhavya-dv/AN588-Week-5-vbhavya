---
title: "Module 9"
author: "Bhavya Deepti Vadavalli"
date: "2023-10-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries
``` {r prelims}
library(curl)
```

## CIs and Standard Error 

```{r ci_and_stderror}
n <- 1000  #is this the population?
mu <- 3.5 
sigma <- 4
v <- rnorm(n, mu, sigma)
s <- sample(v, size = 30, replace = FALSE)
m <- mean(s)
m

sd <- sd(s)
sd

sem <- sd(s)/sqrt(length(s))  #standard error of mean
sem

lower <- m - qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci <- c(lower, upper)
ci
```
## Central Limit Theorem: 

Assumes normality for a distribution (any distribution) if n, the no. of iid samples are large enough. 

CLT that allows us to make inferences about a population based on a sample.

```{r pois_sim}
lambda <- 14
n <- 10
pop_se <- sqrt(lambda/n)  # the estimated SE
pop_se
```
If 1000 samples are taken from the same population (earlier, 10 samples were taken), the plot looks normal. 
```{r pois_to_nd_1000}
x <- NULL
for (i in 1:1000) {
    x[i] <- mean(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(from = lambda - 4 * sqrt(lambda)/sqrt(n), to = lambda +
    4 * sqrt(lambda)/sqrt(n), length.out = 20), probability = TRUE)

sd <- sd(x)  # st dev of the sampling distribution
sd

qqnorm(x) #to check for normality
qqline(x) ##Weird error here?
```
```{r pois_to_nd_100}
n <- 100
pop_se <- sqrt(lambda/n)  # the estimated SE
pop_se

x <- NULL
for (i in 1:100) { #error in Chris' code. it says 1000 instead of 100
    x[i] <- mean(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(from = lambda - 4 * sqrt(lambda)/sqrt(n), to = lambda +
    4 * sqrt(lambda)/sqrt(n), length.out = 20), probability = TRUE)

#doesn't look as normal as earlier

sd <- sd(x)  # st dev of the sampling distribution
sd #a little bit lower

qqnorm(x)
qqline(x)
```

```{r convert_to_std_normal}
curve(dnorm(x, 0, 1), -4, 4, ylim = c(0, 0.8))
z <- (x - lambda)/pop_se
hist(z, breaks = seq(from = -4, to = 4, length.out = 20), probability = TRUE, add = TRUE) #plot.new has not been called?

n <- 100
x <- NULL
for (i in 1:1000) {
    x[i] <- sum(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(min(x), max(x), length.out = 20), probability = TRUE)

n <- 100
x <- NULL
for (i in 1:1000) {
    x[i] <- sum(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(min(x), max(x), length.out = 20), probability = TRUE)
```

## CIs for Sample Proportions: 

```{r phat}
n <- 1000
x <- 856
phat <- x/n  # our estimate of pi
phat

n * phat
n * (1 - phat)

pop_se <- sqrt((phat) * (1 - phat)/n)
```

```{r phat_ci}
curve(dnorm(x, mean = phat, sd = pop_se), phat - 4 * pop_se, phat + 4 * pop_se)
upper <- phat + qnorm(0.975) * pop_se
lower <- phat - qnorm(0.975) * pop_se
ci <- c(lower, upper)
polygon(cbind(c(ci[1], seq(from = ci[1], to = ci[2], length.out = 1000), ci[2]),
    c(0, dnorm(seq(from = ci[1], to = ci[2], length.out = 1000), mean = phat,
        sd = pop_se), 0)), border = "black", col = "gray")
abline(v = ci)
abline(h = 0)
```

## Small sample CIs
n < 30
Instead of z-distribution, we use a t-distribution.

```{r t_distribution}
mu <- 0
sigma <- 1
curve(dnorm(x, mu, 1), mu - 4 * sigma, mu + 4 * sigma, main = "Normal Curve=red\nStudent's t=blue",
    xlab = "x", ylab = "f(x)", col = "red", lwd = 3)
for (i in c(1, 2, 3, 4, 5, 10, 20, 100)) {
    curve(dt(x, df = i), mu - 4 * sigma, mu + 4 * sigma, main = "T Curve", xlab = "x",
        ylab = "f(x)", add = TRUE, col = "blue", lty = 5)
}

n <- 1e+05
mu <- 3.5
sigma <- 4
x <- rnorm(n, mu, sigma)
sample_size <- 30
s <- sample(x, size = sample_size, replace = FALSE)
m <- mean(s)
m

sd <- sd(s)
sd

sem <- sd(s)/sqrt(length(s))
sem
```

```{r comp_of_ci__t_distribution}
lower <- m - qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_norm <- c(lower, upper)
ci_norm
## [1] 1.933577 4.357288


### Sample size 30
lower <- m - qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_t <- c(lower, upper)
ci_t
```

Using a much smaller sample size: 

```{r sample_size_5}
###sample size 5
sample_size <- 5
s <- sample(x, size = sample_size, replace = FALSE)
m <- mean(s)
m

sd <- sd(s)
sd

sem <- sd(s)/sqrt(length(s))
sem

lower <- m - qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_norm <- c(lower, upper)
ci_norm


lower <- m - qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_t <- c(lower, upper)
ci_t
```

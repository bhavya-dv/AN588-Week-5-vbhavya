---
title: "Module 10"
author: "Bhavya Deepti Vadavalli"
date: "2023-10-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries
``` {r prelims}
library(curl)
```

# One-sample t- and z-tests:
```{r one_sample_data}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/vervet-weights.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

mean(d$weight)

mu <- 4.9
x <- d$weight
m <- mean(x)
s <- sd(x)
n <- length(x)
sem <- s/sqrt(n)
```

```{r z_dist_one_sample}
z <- (m - mu)/sem
z
p <- 1 - pnorm(z)
p
p <- pnorm(z, lower.tail = FALSE)
p


p <- 1 - pt(z, df = n - 1)
p
p <- pt(z, df = n - 1, lower.tail = FALSE)
p
```

```{r t_test_one_sample}
t <- t.test(x = x, mu = mu, alternative = "greater")
t


lower <- m - qt(1 - 0.05/2, df = n - 1) * sem
upper <- m + qt(1 - 0.05/2, df = n - 1) * sem
ci <- c(lower, upper)
ci  # by hand

t <- t.test(x = x, mu = mu, alternative = "two.sided")
ci <- t$conf.int
ci  # using t test
```
Do not reject null hypothesis

## Challenge 1
```{r challenge 1}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/woolly-weights.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

x <- d$weight
m <- mean(x)
s <- sd(x)
n <- length(x)
sem <- s/sqrt(n)
mu <- 7.2
t <- (m - mu)/sem
t


alpha <- 0.05
crit <- qt(1 - alpha/2, df = n - 1)  # identify critical values
test <- t < -crit || t > crit  # boolean test as to whether t is larger than the critical value at either tail
test <- abs(t) > crit
t.test(x = x, mu = mu, alternative = "two.sided")
```

p less than 0.05, therefore reject null  hypothesis

# Two-sample tests: 

## Samples with unequal variances

### Challenge 2:

```{r challenge 2}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/colobus-weights.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

x <- d$weight[d$sex == "male"]
y <- d$weight[d$sex == "female"]
par(mfrow = c(1, 2))
boxplot(x, ylim = c(4.5, 8), main = "Weight (kg)", xlab = "Males")
boxplot(y, ylim = c(4.5, 8), main = "Weight (kg)", xlab = "Females")


m1 <- mean(x)
m2 <- mean(y)
mu <- 0  # you could leave this out... the default argument value is 0
s1 <- sd(x)
s2 <- sd(y)
n1 <- length(x)
n2 <- length(y)

###Calculating the t-statistic
t <- (m2 - m1 - mu)/sqrt(s2^2/n2 + s1^2/n1)
t

alpha <- 0.05
crit <- qt(1 - alpha/2, df = n - 1)  # identify critical values
crit

###t-test
test <- t < -crit || t > crit  # boolean test
test <- abs(t) > crit
test

###degrees of freedom
df <- (s2^2/n2 + s1^2/n1)^2/((s2^2/n2)^2/(n2 - 1) + (s1^2/n1)^2/(n1 - 1))
df

t <- t.test(x = x, y = y, mu = 0, alternative = "two.sided")
t
```

## Samples with Equal Variances

```{r 2_sample_eq_var}
s <- sqrt((((n1 - 1) * s1^2) + ((n2 - 1) * s2^2))/(n1 + n2 - 2))
t <- (m2 - m1 - mu)/(sqrt(s^2 * (1/n1 + 1/n2)))
t


df <- n1 + n2 - 2
df

t <- t.test(x = x, y = y, mu = 0, var.equal = TRUE, alternative = "two.sided")
t

var(x)/var(y)

vt <- var.test(x, y)
vt ## This is an F-test

```
## Paired Samples:

### Challenge 3

```{r challenge3}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/iqs.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

x <- d$IQ.before - d$IQ.after
m <- mean(x)
mu <- 0  # can leave this out
s <- sd(x)
n <- length(x)
sem <- s/sqrt(n)
par(mfrow = c(1, 2))
boxplot(d$IQ.before, ylim = c(115, 145), main = "IQ", xlab = "Before")
boxplot(d$IQ.after, ylim = c(115, 145), main = "IQ", xlab = "After")

### t-test
t <- (m - mu)/sem
t

alpha <- 0.05
crit <- qt(1 - alpha/2, df = n - 1)  # identify critical values
crit

test <- t < -crit || t > crit  # boolean test
test

t.test(x, df = n - 1, alternative = "two.sided")

```

## Sample Proportions: One-sample test

```{r prop_one_sample_pop1}
pop <- c(rep(0, 500), rep(1, 500)) #creating a population
pi <- 0.5
x <- NULL
n <- 10
for (i in 1:1000) {
    x[i] <- mean(sample(pop, size = n, replace = FALSE))  # taking the mean of a bunch of 0s and 1s yields the proportion of 1s!
}
m <- mean(x)
m

s <- sd(x)
s

pop_se <- sqrt(pi * (1 - pi)/n)
pop_se  # the se is an estimate of the sd of the sampling distribution
```

```{r prop_one_sample_pop2}
pop <- c(rep(0, 800), rep(1, 200))
pi <- 0.8
x <- NULL
n <- 10
for (i in 1:1000) {
    x[i] <- mean(sample(pop, size = n, replace = FALSE))  # taking the mean of a bunch of 0s and 1s yields the proportion of 1s!
}
m <- mean(x)
m

s <- sd(x)
s

pop_se <- sqrt(pi * (1 - pi)/n)
pop_se  # the se is an estimate of the sd of the sampling distribution
```
### Challenge 4

```{r challenge4}

v <- c(0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,
    1, 1, 0, 1, 0, 1, 1)

phat <- mean(v)
phat

pi <- 0.8
n <- 30
z <- (phat - pi)/sqrt(pi * (1 - pi)/30)
z

p <- pnorm(z, lower.tail = TRUE)
p

lower <- phat - qnorm(0.975) * sqrt(phat * (1 - phat)/30)
upper <- phat + qnorm(0.975) * sqrt(phat * (1 - phat)/30)
ci <- c(lower, upper)
ci #known as the Wald Confidence Interval


###One-liner
pt <- prop.test(x = sum(v), n = length(v), p = 0.8, conf.level = 0.95, correct = FALSE,
    alternative = "less")
pt
```

## Comparing Sample Proportions: Two Sample Z Tests

### Challenge 5

```{r challenge 5}
v1 <- c(1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,
    1, 0)
v2 <- c(1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,
    0, 1, 1, 0, 1, 1, 1)

pstar <- (sum(v1) + sum(v2))/(length(v1) + length(v2))
pstar

phat1 <- mean(v1)
phat1

phat2 <- mean(v2)
phat2

pi <- 0
z <- (phat2 - phat1)/sqrt((pstar * (1 - pstar)) * (1/length(v1) + 1/length(v2)))
z

p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
p

crit <- qnorm(1 - alpha/2)  # identify critical values
crit

test <- p < -crit || p > crit  # boolean test
test

### one-liner 
pt <- prop.test(x = c(sum(v2), sum(v1)), n = c(length(v2), length(v1)), alternative = "two.sided",
    correct = FALSE)
pt
```

FINI!!!
